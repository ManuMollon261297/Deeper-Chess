# -*- coding: utf-8 -*-
"""DBNsup.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ryMts1CQWRBt11u4wV_j-yKUD8fMd0pk
"""

#https://software.intel.com/content/www/us/en/develop/articles/keras-implementation-of-siamese-like-networks.html
#https://martin-thoma.com/siamese-networks/
#https://medium.com/@bramblexu/softmax-output-neurons-number-for-binary-classification-1e4bf91a2ffe
#https://github.com/aspamers/siamese/blob/master/siamese.py

# Load Libraries
import numpy as np
import tensorflow as tf
import pandas as pd
import timeit
import random

from keras import backend as K
from keras import initializers
from keras import activations
from keras.models import Model, Sequential, load_model
from keras.layers import Concatenate, Conv2D, MaxPooling2D, Dense,Input, Flatten 
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback
from keras.optimizers import Adam
from keras.engine import InputSpec, Layer 
from keras import regularizers
from keras.utils.conv_utils import conv_output_length 

def trimAutoencoder(model):
  for i in range(int(len(model.layers)/2)):
    model.pop()
  return model

base_model = load_model('temp.h5')
base_model = trimAutoencoder(base_model)
for layer in base_model.layers:
  layer.trainable = True

base_model.summary()

input1 = Input(shape=(100,))
input2 = Input(shape=(100,))
merged = Concatenate(axis=1)([input1, input2])
dense1 = Dense(400, activation='relu')(merged)
dense2 = Dense(200, activation='relu')(dense1)
dense3 = Dense(100, activation='relu')(dense2)
output = Dense(2, activation='softmax')(dense3)
head_model = Model([input1, input2], output)

head_model.summary()

# -------------------------------------------------------------------
# input1 -> base_model |
#                       --> embedding --> head_model --> binary output
# input2 -> base_model |
# -------------------------------------------------------------------

"""
Create the siamese model structure using the supplied base and head model.
"""
input_a = Input(shape=(773,))
input_b = Input(shape=(773,))

processed_a = base_model(input_a)
processed_b = base_model(input_b)

head = head_model([processed_a, processed_b])
siamese_model = Model([input_a, input_b], head)

siamese_model.summary()

opt = Adam()
siamese_model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])

gamesBarray = np.load('bitStreamPosDataFinalB.npy') 
gamesWarray = np.load('bitStreamPosDataFinalW.npy')

print(len(gamesWarray))
print(len(gamesBarray)) 

num_epochs = 1
batch_size = 256

xTrain1 = np.zeros((1000000,773), dtype=np.int8) 
xTrain2 = np.zeros((1000000,773), dtype=np.int8) 
yTrain = np.zeros((1000000,2), dtype=np.int8)

for k in range(1000):
  print('New Epoch:')
  print(k, end="\r")
  for j in range(1000000):
    print('New Epoch Data Generation:')
    print(j, end="\r")
    gameB = random.randint(0,len(gamesBarray)-1)
    gameW = random.randint(0,len(gamesWarray)-1)
    side = random.randint(0,1)
    if side:
      xTrain1[j] = gamesBarray[gameB]
      xTrain2[j] = gamesWarray[gameW]
      yTrain[j] = [0,1] 
    else:
      xTrain1[j] = gamesWarray[gameW]
      xTrain2[j] = gamesBarray[gameB]
      yTrain[j] = [1,0]
  siamese_model.fit(x=[xTrain1, xTrain2], y=yTrain,
                    epochs=num_epochs,
                    batch_size=batch_size,
                    shuffle=True,
                    verbose=1)
  siamese_model.save('DBNweights.h5')